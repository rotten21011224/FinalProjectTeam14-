{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class FinalProject:\n",
    "    \n",
    "    def __init__(self, headless = True):\n",
    "\n",
    "        from selenium import webdriver\n",
    "\n",
    "        option = webdriver.ChromeOptions()\n",
    "        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "        if headless:\n",
    "            option.add_argument('--headless')       #隱藏頁面\n",
    "        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "        self.driver = driver    #設定好的driver\n",
    "        self.set_dictionary()\n",
    "        \n",
    "    def set_dictionary(self):\n",
    "        self.dictionary = {}\n",
    "        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\"]\n",
    "        for website in websites:\n",
    "            self.dictionary[website] = {}\n",
    "        \n",
    "    def wait_and_find(self, by, path):\n",
    "        locator = (by, path)\n",
    "        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "        method = eval(\"self.driver.find_element_by_\" + str(by).split(\".\")[-1].lower())\n",
    "        return method(path)\n",
    "    \n",
    "    def wait_and_finds(self, by, path):\n",
    "        locator = (by, path)\n",
    "        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "        return method(path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def print4(title, time, summary, link):\n",
    "        print(\"title: \",title)\n",
    "        if time != None:\n",
    "            print(\"time: \",time)\n",
    "        if summary != None:\n",
    "            print(\"summary:\",summary)\n",
    "        print(\"link: \",link)\n",
    "        print()\n",
    "    \n",
    "    def udn(self, search):\n",
    "        if search in self.dictionary[\"udn\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"udn\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://udn.com/search/result/2/\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"udn\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "            #print(search_content)\n",
    "            for i in search_content:\n",
    "                link = i.get(\"href\")\n",
    "                title = i.find(\"h2\").text\n",
    "                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                summary = i.find(\"p\").text\n",
    "                self.dictionary[\"udn\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "                \n",
    "    def chinatimes(self, search):\n",
    "        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"chinatimes\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"chinatimes\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                if i.get(\"id\") == None:\n",
    "                    h3 = i.find(\"h3\")\n",
    "                    title = h3.text\n",
    "                    a = h3.find(\"a\")\n",
    "                    link = a.get(\"href\")\n",
    "                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                    summary = i.find(\"p\").text\n",
    "                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link))\n",
    "                    FinalProject.print4(title, time, summary, link)\n",
    "                    \n",
    "    def tvbs(self, search):\n",
    "        if search in self.dictionary[\"tvbs\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"tvbs\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "            self.driver.get(html)        \n",
    "            self.dictionary[\"tvbs\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                a = i.find(\"a\")\n",
    "                link = a.get(\"href\")\n",
    "                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                self.dictionary[\"tvbs\"][search].append((title, time, None, link))\n",
    "                FinalProject.print4(title, time, None, link)\n",
    "    \n",
    "    def nownews(self, search):\n",
    "        if search in self.dictionary[\"nownews\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"nownews\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"nownews\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "            for i in search_content:\n",
    "                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                time, summary = temp[0], temp[1]\n",
    "                self.dictionary[\"nownews\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "\n",
    "    def ftvnews(self, search):\n",
    "        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"ftvnews\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"ftvnews\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                title = i.find(\"div\", class_ = \"title\").text\n",
    "                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "                \n",
    "    def apple(self, search):\n",
    "        if search in self.dictionary[\"apple\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"apple\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"apple\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "            for i in search_content:\n",
    "                a = i.find(\"a\")\n",
    "                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                time = i.find(\"time\").text\n",
    "                self.dictionary[\"apple\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "                \n",
    "    def ltn(self, search):\n",
    "        if search in self.dictionary[\"ltn\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"ltn\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"ltn\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                time = i.find(\"span\").text\n",
    "                a = i.find(\"a\", class_ = \"tit\")\n",
    "                title, link = a.text, a.get(\"href\")\n",
    "                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                self.dictionary[\"ltn\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "                \n",
    "    def google(self, search):\n",
    "        if search in self.dictionary[\"google\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"google\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \"https://www.google.com/search?q=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"google\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "            try:\n",
    "                for i in search_content:\n",
    "                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                    title = h3.text\n",
    "                    a = h3.find_parent(\"a\")\n",
    "                    link = a.get(\"href\")\n",
    "                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                    self.dictionary[\"google\"][search].append((title, None, summary, link))\n",
    "                    FinalProject.print4(title, None, summary, link)\n",
    "            except:\n",
    "                pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = FinalProject(False)\n",
    "driver.google(\"韓國瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.google(\"韓國瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def (self, search):\n",
    "        if search in self.dictionary[\"\"].keys():\n",
    "            for title, time, summary, link in self.dictionary[\"\"][search]:\n",
    "                FinalProject.print4(title, time, summary, link)\n",
    "        else:\n",
    "            html = \n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = \n",
    "            for i in search_content:                \n",
    "                self.dictionary[\"\"][search].append((title, time, summary, link))\n",
    "                FinalProject.print4(title, time, summary, link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
