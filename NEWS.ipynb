{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class FinalProject:\n",
    "    \n",
    "    def __init__(self, headless = True):\n",
    "\n",
    "        from selenium import webdriver\n",
    "\n",
    "        option = webdriver.ChromeOptions()\n",
    "        option.add_argument('--lang=zh_TW-ZH_TW')   #繁體中文\n",
    "        if headless:\n",
    "            option.add_argument('--headless')       #隱藏頁面\n",
    "        driver = webdriver.Chrome('./chromedriver', options=option)\n",
    "        self.driver = driver    #設定好的driver\n",
    "        self.set_dictionary()\n",
    "        \n",
    "    def set_dictionary(self):\n",
    "        self.dictionary = {}\n",
    "        websites = [\"udn\", \"chinatimes\", \"tvbs\", \"nownews\", \"ftvnews\", \"apple\", \"ltn\", \"google\", \"yahoo\", \"youtube\", \"bing\"]\n",
    "        for website in websites:\n",
    "            self.dictionary[website] = {}\n",
    "        \n",
    "    def wait_and_find(self, by, path):\n",
    "        locator = (by, path)\n",
    "        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "        method = eval(\"self.driver.find_element_by_\" + \"_\".join(str(by).split(\".\")[-1].lower().split()))\n",
    "        return method(path)\n",
    "    \n",
    "    def wait_and_finds(self, by, path):\n",
    "        locator = (by, path)\n",
    "        WebDriverWait(self.driver, 10, 0.5).until(EC.presence_of_element_located(locator))\n",
    "        method = eval(\"self.driver.find_elements_by_\" + str(by).split(\".\")[-1].lower())\n",
    "        return method(path)\n",
    "    \n",
    "    @staticmethod\n",
    "    def print5(title, time, summary, link, picture):\n",
    "        print(\"title: \",title)\n",
    "        if time != None:\n",
    "            print(\"time: \",time)\n",
    "        if summary != None:\n",
    "            print(\"summary:\",summary)\n",
    "        print(\"link: \",link)\n",
    "        print(\"picture: \", picture)\n",
    "        print()\n",
    "        \n",
    "    @staticmethod\n",
    "    def imagepath():\n",
    "\n",
    "        import os\n",
    "        from tkinter import filedialog\n",
    "\n",
    "        default_dir = r\"C:\\Users\\Desktop\"  # 設置默認打開目錄\n",
    "        fname = filedialog.askopenfilename(title=u\"選擇圖片\",initialdir=(os.path.expanduser(default_dir)))\n",
    "\n",
    "        return fname # 文件絕對路徑\n",
    "\n",
    "    @staticmethod\n",
    "    def path_is_image(path):\n",
    "\n",
    "        import imghdr\n",
    "        img = imghdr.what(path)   #檢查路徑是否為圖片\n",
    "\n",
    "        if img != None:\n",
    "            return True\n",
    "        return False \n",
    "        \n",
    "    def google_image(self):\n",
    "        \n",
    "        imagepath = FinalProject.imagepath()\n",
    "        while  imagepath == \"\" or not (FinalProject.path_is_image(imagepath)) :\n",
    "            print(\"請選擇一張圖片!!\")\n",
    "            imagepath = FinalProject.imagepath()\n",
    "\n",
    "        #打開google圖片\n",
    "        self.driver.get('https://www.google.com.tw/imghp')\n",
    "        imagebutton = self.wait_and_find(By.CLASS_NAME, \"LM8x9c\")\n",
    "        imagebutton.click()\n",
    "\n",
    "        #傳送圖片\n",
    "        image = self.wait_and_find(By.NAME, \"encoded_image\")\n",
    "        image.send_keys(imagepath)\n",
    "\n",
    "        #取得搜尋結果\n",
    "        q = self.wait_and_find(By.NAME, \"q\")\n",
    "        image_response = q.get_attribute(\"value\")\n",
    "\n",
    "        return image_response\n",
    "\n",
    "    def google_translate(self, image_response):\n",
    "\n",
    "        #打開google翻譯並輸入文字\n",
    "        self.driver.get('https://translate.google.com/')\n",
    "        transinput = self.wait_and_find(By.ID, \"source\")\n",
    "        transinput.send_keys(image_response)\n",
    "\n",
    "        #取得中文翻譯以及原文語言\n",
    "        translate_response = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]\"\"\").text        \n",
    "        lang = self.driver.find_element_by_xpath(\"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[1]/div[1]/div[1]/div[1]/div[2]/div[1]\"\"\").text.split()[0]\n",
    "\n",
    "        print()\n",
    "        print(\"中文: \" + translate_response)\n",
    "        print()\n",
    "\n",
    "        #取得英文翻譯\n",
    "        if lang == \"英文\":\n",
    "            print(\"英文: \" + image_response)\n",
    "        else:\n",
    "            englishbutton = self.driver.find_elements_by_id(\"sugg-item-en\")[1]\n",
    "            englishbutton.click()    #點擊英文翻譯\n",
    "            english = self.wait_and_find(By.XPATH, \"\"\"/html/body/div[2]/div[1]/div[2]/div[1]/div[1]/div[2]/div[3]/div[1]/div[2]/div/span[1]/span\"\"\").text\n",
    "            print(\"英文: \" + english)\n",
    "\n",
    "            if lang != \"中文\":\n",
    "                #原文非中文,英文\n",
    "                print(lang + \": \" + image_response)\n",
    "        print()\n",
    "\n",
    "        return translate_response\n",
    "\n",
    "    def wikipedia(self, translate_response):\n",
    "        #查詢維基百科\n",
    "        self.driver.get(\"https://www.google.com.tw/\")\n",
    "        q = self.wait_and_find(By.NAME, \"q\")\n",
    "        q.send_keys(translate_response+\" 維基百科\")\n",
    "        q.send_keys(Keys.RETURN)\n",
    "\n",
    "        #點擊第一項名字有維基百科的搜尋結果\n",
    "        self.wait_and_find(By.CLASS_NAME, \"q\")\n",
    "        g = self.driver.find_elements_by_class_name(\"LC20lb\")\n",
    "        for title in g:\n",
    "            if \"維基百科\" in title.text:\n",
    "                title.click()\n",
    "                break\n",
    "\n",
    "        #找尋解釋文字\n",
    "        wikitext = self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "        print(wikitext)\n",
    "\n",
    "        try:      \n",
    "            disambiguation = self.wait_and_find(By.CLASS_NAME,\"mbox-text\")\n",
    "\n",
    "            if \"消歧義\" in disambiguation.text or \"消歧义\" in disambiguation.text:\n",
    "                #處理消歧義頁面問題 \n",
    "                alldisambiguation = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")            \n",
    "                l = len(alldisambiguation)   #取得子頁面數量\n",
    "\n",
    "                for i in range(l):\n",
    "                    print()\n",
    "                    disambiguation_i = self.wait_and_find(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li/a[1]\"\"\")[i]\n",
    "                    disambiguation_i_text = self.driver.find_elements_by_xpath(\"\"\"//*[@id=\"mw-content-text\"]/div/ul/li\"\"\")[i].text\n",
    "                    print(disambiguation_i_text)   #子頁面名稱\n",
    "                    disambiguation_i.click()\n",
    "\n",
    "                    #取得子頁面解釋\n",
    "                    subtext = self.self.wait_and_find(By.XPATH,\"\"\"//*[@id=\"mw-content-text\"]/div/p\"\"\").text\n",
    "                    print(subtext)\n",
    "                    self.driver.back()\n",
    "        except:\n",
    "            #無消歧義\n",
    "            pass\n",
    "        print()\n",
    "\n",
    "    def cezisuanming(self, translate_response):\n",
    "\n",
    "        #打開諸葛神數\n",
    "        self.driver.get('https://www.ximizi.net/zhuge_shenshu.php')\n",
    "        poeminput = self.wait_and_find(By.NAME,\"cezisuanming\")\n",
    "        poeminput.send_keys(translate_response)     #輸入中文\n",
    "        poeminput.send_keys(Keys.RETURN)\n",
    "\n",
    "        #取得籤詩及其解釋\n",
    "        poem = self.wait_and_find(By.XPATH,\"\"\"/html/body/div[1]/div[6]/div[3]/p[2]/font\"\"\").text  \n",
    "        poem_analysis = self.driver.find_element_by_xpath(\"\"\"/html/body/div[1]/div[6]/div[3]/p[3]\"\"\").text\n",
    "\n",
    "        print(\"籤詩: \" + poem)\n",
    "        print()\n",
    "        print(poem_analysis)\n",
    "        print()\n",
    "    \n",
    "    def udn(self, search):\n",
    "        if search in self.dictionary[\"udn\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"udn\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://udn.com/search/result/2/\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"udn\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", id = \"search_content\").find_all(\"a\")\n",
    "            for i in search_content:\n",
    "                link = i.get(\"href\")\n",
    "                title = i.find(\"h2\").text\n",
    "                time = i.find(\"span\").text.split(\"：\")[-1]\n",
    "                summary = i.find(\"p\").text\n",
    "                picture = i.find(\"img\").get(\"src\")\n",
    "                self.dictionary[\"udn\"][search].append((title, time, summary, link, picture))\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "                \n",
    "    def chinatimes(self, search):\n",
    "        if search in self.dictionary[\"chinatimes\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"chinatimes\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.chinatimes.com/search/\" + search + \"?chdtv\"\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"chinatimes\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ul\", class_ = \"vertical-list list-style-none\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                if i.get(\"id\") == None:\n",
    "                    h3 = i.find(\"h3\")\n",
    "                    title = h3.text\n",
    "                    a = h3.find(\"a\")\n",
    "                    link = a.get(\"href\")\n",
    "                    time_list = i.find(\"time\").find_all(\"span\")\n",
    "                    time = time_list[0].text + \" \" + time_list[1].text\n",
    "                    summary = i.find(\"p\").text\n",
    "                    picture = i.find(\"img\").get(\"src\")\n",
    "                    self.dictionary[\"chinatimes\"][search].append((title, time, summary, link, picture))\n",
    "                    FinalProject.print5(title, time, summary, link, picture)\n",
    "                    \n",
    "    def tvbs(self, search):\n",
    "        if search in self.dictionary[\"tvbs\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"tvbs\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://news.tvbs.com.tw/news/searchresult/news?search_text=\" + search\n",
    "            self.driver.get(html)        \n",
    "            self.dictionary[\"tvbs\"][search] = []\n",
    "            soup = BeautifulSoup(self.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", class_ = \"search_list_div\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                a = i.find(\"a\")\n",
    "                link = a.get(\"href\")\n",
    "                title = a.find(\"div\", class_ = \"search_list_txt\").text\n",
    "                time = a.find(\"div\", class_ = \"icon_time\").text\n",
    "                picture = i.find(\"img\").get(\"src\")\n",
    "                self.dictionary[\"tvbs\"][search].append((title, time, None, link, picture))\n",
    "                FinalProject.print5(title, time, None, link, picture)\n",
    "    \n",
    "    def nownews(self, search):\n",
    "        if search in self.dictionary[\"nownews\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"nownews\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.nownews.com/contentsearch/?q=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"nownews\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find_all(\"div\", class_ = \"gsc-webResult gsc-result\")\n",
    "            for i in search_content:\n",
    "                gs_title = i.find(\"a\", class_ = \"gs-title\")\n",
    "                title, link= gs_title.text, gs_title.get(\"href\")\n",
    "                temp = i.find(\"div\", class_ = \"gs-bidi-start-align gs-snippet\").text.split(\"...\")\n",
    "                time, summary = temp[0], temp[1]\n",
    "                picture = i.find(\"img\").get(\"src\")\n",
    "                self.dictionary[\"nownews\"][search].append((title, time, summary, link, picture))\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "\n",
    "    def ftvnews(self, search):\n",
    "        if search in self.dictionary[\"ftvnews\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"ftvnews\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.ftvnews.com.tw/search?key=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"ftvnews\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"section\", class_ = \"search-list clearfix\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                link = \"https://www.ftvnews.com.tw/\" + i.find(\"a\").get(\"href\")\n",
    "                time = \" \".join(i.find(\"span\", class_ = \"time\").text.split())\n",
    "                title = i.find(\"div\", class_ = \"title\").text\n",
    "                summary = i.find(\"div\", class_ = \"summary\").text\n",
    "                picture = i.find(\"img\").get(\"src\")\n",
    "                self.dictionary[\"ftvnews\"][search].append((title, time, summary, link, picture))\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "                \n",
    "    def apple(self, search):\n",
    "        if search in self.dictionary[\"apple\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"apple\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://tw.appledaily.com/search/result?querystrS=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"apple\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ol\", id = \"result\").find_all(\"div\", class_ = \"content\")    \n",
    "            for i in search_content:\n",
    "                a = i.find(\"a\")\n",
    "                title, link = \" \".join(a.text.split()), a.get(\"href\")\n",
    "                summary = i.find(\"p\", class_ = \"ellipsis\").text\n",
    "                time = i.find(\"time\").text\n",
    "                self.dictionary[\"apple\"][search].append((title, time, summary, link, None))\n",
    "                FinalProject.print5(title, time, summary, link, None)\n",
    "                \n",
    "    def ltn(self, search):\n",
    "        if search in self.dictionary[\"ltn\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"ltn\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://news.ltn.com.tw/search?keyword=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"ltn\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ul\", class_ = \"searchlist boxTitle\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                time = i.find(\"span\").text\n",
    "                a = i.find(\"a\", class_ = \"tit\")\n",
    "                title, link = a.text, a.get(\"href\")\n",
    "                summary = \"\".join(i.find(\"p\").text.split())\n",
    "                picture = i.find(\"img\").get(\"src\")\n",
    "                self.dictionary[\"ltn\"][search].append((title, time, summary, link, None))\n",
    "                FinalProject.print5(title, time, summary, link, None)\n",
    "                \n",
    "    def google(self, search):\n",
    "        if search in self.dictionary[\"google\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"google\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.google.com/search?q=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"google\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find_all(\"div\", class_ = \"g\")\n",
    "            for i in search_content:\n",
    "                try:\n",
    "                    h3 = i.find(\"h3\", class_ = \"LC20lb\")\n",
    "                    title = h3.text\n",
    "                    a = h3.find_parent(\"a\")\n",
    "                    link = a.get(\"href\")\n",
    "                    summary = i.find(\"span\", class_ = \"st\").text\n",
    "                    self.dictionary[\"google\"][search].append((title, None, summary, link, None))\n",
    "                    FinalProject.print5(title, None, summary, link, None)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "    def yahoo(self, search):\n",
    "        if search in self.dictionary[\"yahoo\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"yahoo\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://tw.search.yahoo.com/search?p=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"yahoo\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", id = \"web\").find_all(\"li\", class_ = None)\n",
    "            for i in search_content:\n",
    "                try:\n",
    "                    h3 = i.find(\"h3\", class_ = \"title\")\n",
    "                    title = h3.text\n",
    "                    link = h3.find(\"a\").get(\"href\")\n",
    "                    summary = i.find(\"div\", class_ = \"compText aAbs\").text\n",
    "                    self.dictionary[\"yahoo\"][search].append((title, None, summary, link, None))\n",
    "                    FinalProject.print5(title, None, summary, link, None)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    def youtube(self, search):\n",
    "        if search in self.dictionary[\"youtube\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"youtube\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.youtube.com/results?search_query=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"youtube\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"div\", class_ = \"style-scope ytd-vertical-list-renderer\").find_all(\"ytd-video-renderer\")\n",
    "            #print(search_content)\n",
    "            for i in search_content:\n",
    "                a = i.find(\"a\", id = \"thumbnail\")\n",
    "                link = \"https://www.youtube.com\" + a.get(\"href\")\n",
    "                picture = a.find(\"img\").get(\"src\")\n",
    "                title = \"\".join(i.find(\"div\", id = \"title-wrapper\").find(\"h3\").text.split())\n",
    "                time = \" \".join(i.find(\"div\", id = \"metadata\").text.split())\n",
    "                summary = \"\".join(i.find(\"yt-formatted-string\", id = \"description-text\").text.split())\n",
    "                self.dictionary[\"youtube\"][search].append((title, time, summary, link, picture))\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "                \n",
    "    def bing(self, search):\n",
    "        if search in self.dictionary[\"bing\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"bing\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \"https://www.bing.com/search?q=\" + search\n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"bing\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = soup.find(\"ol\", id = \"b_results\").find_all(\"li\")\n",
    "            for i in search_content:\n",
    "                try:\n",
    "                    a = i.find(\"a\")\n",
    "                    title, link = a.text, a.get(\"href\")\n",
    "                    summary = i.find(\"div\", class_ = \"b_caption\").find(\"p\").text\n",
    "                    self.dictionary[\"bing\"][search].append((title, None, summary, link, None))\n",
    "                    FinalProject.print5(title, None, summary, link, None)\n",
    "                except:\n",
    "                    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver = FinalProject()\n",
    "driver.nownews(\"韓國瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"self.driver.find_element_by_\" + str(By.CLASS_NAME).split(\".\")[-1].lower())\n",
    "By.CLASS_NAME.split(\".\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.bing(\"韓國瑜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def (self, search):\n",
    "        if search in self.dictionary[\"\"].keys():\n",
    "            for title, time, summary, link, picture in self.dictionary[\"\"][search]:\n",
    "                FinalProject.print5(title, time, summary, link, picture)\n",
    "        else:\n",
    "            html = \n",
    "            self.driver.get(html)\n",
    "            self.dictionary[\"\"][search] = []\n",
    "            soup = BeautifulSoup(driver.driver.page_source, \"html.parser\")\n",
    "            search_content = \n",
    "            for i in search_content:                \n",
    "                self.dictionary[\"\"][search].append((title, time, summary, link, picture))\n",
    "                FinalProject.print5(title, time, summary, link, picture)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
